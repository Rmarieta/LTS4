{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this if using cov matrix\n",
    "is_cov = True\n",
    "\n",
    "\n",
    "\n",
    "# Keep data in 2D for 2D convolution of the NN\n",
    "def load_graphs(input_dir, class_dict) :\n",
    "\n",
    "    data, data_labels = [], [] # data containing the graphs and data_labels the associated seizure type labels\n",
    "    i=0\n",
    "    for szr_type in class_dict.keys() :\n",
    "        szr_label = class_dict[szr_type]\n",
    "        for _, _, files in os.walk(os.path.join(input_dir,szr_type)) :\n",
    "            for npy_file in files :\n",
    "                A = np.load(os.path.join(input_dir,szr_type,npy_file))\n",
    "\n",
    "                # Normalise A (already normalised depending on the input)\n",
    "                #A = A/np.amax(A.flatten())\n",
    "                if is_cov : \n",
    "                    L = torch.tensor(A/np.amax(A.flatten())).view(1,20,20)\n",
    "                else : \n",
    "                    L = torch.tensor(np.diag(A*np.ones((A.shape[0],1)))-A).view(1,20,20)\n",
    "                    #L = torch.tensor(A).view(1,20,20)\n",
    "\n",
    "                data.append(L)\n",
    "                data_labels.append(szr_label)\n",
    "\n",
    "    return np.array(data), np.array(data_labels)\n",
    "\n",
    "def train_test_data(input_dir, class_dict) :\n",
    "\n",
    "    train, train_labels = load_graphs(os.path.join(input_dir,'train'), class_dict)\n",
    "    test, test_labels = load_graphs(os.path.join(input_dir,'dev'), class_dict)\n",
    "\n",
    "    return train, test, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rapha\\AppData\\Local\\Temp/ipykernel_4304/2000065660.py:28: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  return np.array(data), np.array(data_labels)\n",
      "C:\\Users\\rapha\\AppData\\Local\\Temp/ipykernel_4304/2000065660.py:28: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(data), np.array(data_labels)\n"
     ]
    }
   ],
   "source": [
    "# Need to put it as a torch.Size([1, 20, 20])\n",
    "input_dir = '../data/v1.5.2/graph_cov_low'\n",
    "szr_types = ['FNSZ','GNSZ']\n",
    "\n",
    "class_dict = {}\n",
    "for i, szr_type in enumerate(szr_types) :\n",
    "    class_dict[szr_type] = i\n",
    "\n",
    "train, test, train_labels, test_labels = train_test_data(input_dir, class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536  vs  409\n",
      "3\n",
      "309\n"
     ]
    }
   ],
   "source": [
    "# Oversampling (train set only) to have balanced classification without dropping information\n",
    "PD = pd.DataFrame(train_labels,columns=['label'])\n",
    "no_0, no_1 = len(PD[PD['label']==0]), len(PD[PD['label']==1])\n",
    "print(no_0, ' vs ', no_1)\n",
    "\n",
    "R = math.floor(no_0/no_1)\n",
    "print(R) # Multiply the dataset by this ratio, then add (no_0 - R*no_1) randomly selected entries from the smallest dataset\n",
    "print(no_0 - R*no_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "trainset, testset = [], []\n",
    "for i in range(len(train)) :\n",
    "    if train_labels[i] == 1 : # Under-represented class :\n",
    "        # The dataloader later shuffles the data\n",
    "        for r in range(R) :\n",
    "            trainset.append((train[i],train_labels[i]))\n",
    "    else :\n",
    "        trainset.append((train[i],train_labels[i]))\n",
    "\n",
    "# Compensate the remaining imbalance => draw (no_0 - R*no_1) elements from already present elements\n",
    "Add = random.sample(PD[PD['label']==1].index.to_list(),no_0 - R*no_1)\n",
    "for idx in Add :\n",
    "    trainset.append((train[idx],train_labels[idx]))\n",
    "\n",
    "for j in range(len(test)) :\n",
    "    testset.append((test[j],test_labels[j]))\n",
    "classes = ('FNSZ','GNSZ')\n",
    "\n",
    "#trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "#testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536  vs  1536\n"
     ]
    }
   ],
   "source": [
    "len(trainset)\n",
    "tmp_set = []\n",
    "for s in trainset :\n",
    "    tmp_set.append(s[1])\n",
    "\n",
    "PD_tmp = pd.DataFrame(tmp_set,columns=['label'])\n",
    "tmp_0, tmp_1 = len(PD_tmp[PD_tmp['label']==0]), len(PD_tmp[PD_tmp['label']==1])\n",
    "print(tmp_0, ' vs ', tmp_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.fc1 = nn.Linear(16 * 3 * 3, 80)\n",
    "        self.fc2 = nn.Linear(80, 40)\n",
    "        self.fc3 = nn.Linear(40, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nclass Net_2(nn.Module):\\n    def __init__(self):\\n        super().__init__()\\n        self.conv1 = nn.Conv2d(3, 6, 5)\\n        self.pool = nn.MaxPool2d(2, 2)\\n        self.conv2 = nn.Conv2d(6, 16, 5)\\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\\n        self.fc2 = nn.Linear(120, 84)\\n        self.fc3 = nn.Linear(84, 10)\\n\\n    def forward(self, x):\\n        x = self.pool(F.relu(self.conv1(x)))\\n        x = self.pool(F.relu(self.conv2(x)))\\n        print('Before : ',x.shape)\\n        x = torch.flatten(x, 1) # flatten all dimensions except batch\\n        print('After : ',x.shape)\\n        x = F.relu(self.fc1(x))\\n        x = F.relu(self.fc2(x))\\n        x = self.fc3(x)\\n        return x\\n\\nCNN = Net_2()\\nCNN = CNN.float()\\ncriterion = nn.CrossEntropyLoss()\\noptimizer = optim.SGD(CNN.parameters(), lr=0.001, momentum=0.9)\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "class Net_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        print('Before : ',x.shape)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        print('After : ',x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "CNN = Net_2()\n",
    "CNN = CNN.float()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(CNN.parameters(), lr=0.001, momentum=0.9)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=144, out_features=80, bias=True)\n",
      "  (fc2): Linear(in_features=80, out_features=40, bias=True)\n",
      "  (fc3): Linear(in_features=40, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Run forward pass once and check flattened output dimensions\n",
    "CNN = Net()\n",
    "CNN = CNN.float()\n",
    "print(CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 1e-4\n",
    "loss_criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(CNN.parameters(), lr=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch_size :  50 \n",
      "Learning rate :  0.0001\n",
      "Loss : 0.6931041479110718, epoch(0)\n",
      "Loss : 0.692186713218689, epoch(1)\n",
      "Loss : 0.6911152601242065, epoch(2)\n",
      "Loss : 0.6897179484367371, epoch(3)\n",
      "Loss : 0.6872988939285278, epoch(4)\n",
      "Loss : 0.6832760572433472, epoch(5)\n",
      "Loss : 0.6773010492324829, epoch(6)\n",
      "Loss : 0.6692423224449158, epoch(7)\n",
      "Loss : 0.6596786379814148, epoch(8)\n",
      "Loss : 0.6511512398719788, epoch(9)\n",
      "Loss : 0.6423380970954895, epoch(10)\n",
      "Loss : 0.6356598138809204, epoch(11)\n",
      "Loss : 0.6290466785430908, epoch(12)\n",
      "Loss : 0.6233619451522827, epoch(13)\n",
      "Loss : 0.6162059903144836, epoch(14)\n",
      "Loss : 0.6114842891693115, epoch(15)\n",
      "Loss : 0.6042594909667969, epoch(16)\n",
      "Loss : 0.6017147302627563, epoch(17)\n",
      "Loss : 0.5963217616081238, epoch(18)\n",
      "Loss : 0.5899702310562134, epoch(19)\n",
      "Loss : 0.5863354802131653, epoch(20)\n",
      "Loss : 0.5815142393112183, epoch(21)\n",
      "Loss : 0.577069878578186, epoch(22)\n",
      "Loss : 0.5726605653762817, epoch(23)\n",
      "Loss : 0.5687516331672668, epoch(24)\n",
      "Loss : 0.564361572265625, epoch(25)\n",
      "Loss : 0.5593436360359192, epoch(26)\n",
      "Loss : 0.5552555918693542, epoch(27)\n",
      "Loss : 0.5528901815414429, epoch(28)\n",
      "Loss : 0.5497872829437256, epoch(29)\n",
      "Loss : 0.5420178174972534, epoch(30)\n",
      "Loss : 0.5372055768966675, epoch(31)\n",
      "Loss : 0.534308910369873, epoch(32)\n",
      "Loss : 0.5278534889221191, epoch(33)\n",
      "Loss : 0.5234338045120239, epoch(34)\n",
      "Loss : 0.5188156962394714, epoch(35)\n",
      "Loss : 0.5155470967292786, epoch(36)\n",
      "Loss : 0.5121132135391235, epoch(37)\n",
      "Loss : 0.5092222094535828, epoch(38)\n",
      "Loss : 0.5052050352096558, epoch(39)\n",
      "Loss : 0.5036601424217224, epoch(40)\n",
      "Loss : 0.4997013807296753, epoch(41)\n",
      "Loss : 0.4984166622161865, epoch(42)\n",
      "Loss : 0.4970368444919586, epoch(43)\n",
      "Loss : 0.49303850531578064, epoch(44)\n",
      "Loss : 0.49155351519584656, epoch(45)\n",
      "Loss : 0.4908648431301117, epoch(46)\n",
      "Loss : 0.48814165592193604, epoch(47)\n",
      "Loss : 0.48586878180503845, epoch(48)\n",
      "Loss : 0.48447105288505554, epoch(49)\n",
      "Loss : 0.48315632343292236, epoch(50)\n",
      "Loss : 0.4812764823436737, epoch(51)\n",
      "Loss : 0.4799902141094208, epoch(52)\n",
      "Loss : 0.47847768664360046, epoch(53)\n",
      "Loss : 0.47650882601737976, epoch(54)\n",
      "Loss : 0.47465750575065613, epoch(55)\n",
      "Loss : 0.475789874792099, epoch(56)\n",
      "Loss : 0.473471462726593, epoch(57)\n",
      "Loss : 0.47219914197921753, epoch(58)\n",
      "Loss : 0.4706681966781616, epoch(59)\n",
      "Loss : 0.46891772747039795, epoch(60)\n",
      "Loss : 0.4676220417022705, epoch(61)\n",
      "Loss : 0.468016654253006, epoch(62)\n",
      "Loss : 0.4678972661495209, epoch(63)\n",
      "Loss : 0.464620441198349, epoch(64)\n",
      "Loss : 0.46360644698143005, epoch(65)\n",
      "Loss : 0.4639323949813843, epoch(66)\n",
      "Loss : 0.46109721064567566, epoch(67)\n",
      "Loss : 0.4604281485080719, epoch(68)\n",
      "Loss : 0.45976004004478455, epoch(69)\n",
      "Loss : 0.4580978751182556, epoch(70)\n",
      "Loss : 0.4577428996562958, epoch(71)\n",
      "Loss : 0.45667916536331177, epoch(72)\n",
      "Loss : 0.45547550916671753, epoch(73)\n",
      "Loss : 0.4557165503501892, epoch(74)\n",
      "Loss : 0.45344245433807373, epoch(75)\n",
      "Loss : 0.45468413829803467, epoch(76)\n",
      "Loss : 0.4521833658218384, epoch(77)\n",
      "Loss : 0.45089855790138245, epoch(78)\n",
      "Loss : 0.4504678547382355, epoch(79)\n"
     ]
    }
   ],
   "source": [
    "total_L, total_acc = [], []\n",
    "print('Batch_size : ',batch_size,'\\nLearning rate : ',gamma)\n",
    "for epoch in range(80): \n",
    "    i = 0\n",
    "    temp_L = []\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in trainloader:\n",
    "        X, y = data\n",
    "        optimizer.zero_grad()\n",
    "        X, y = X.float(), y.type(torch.LongTensor)\n",
    "        output = CNN(X)\n",
    "        #if i == 0 : print(output.data[:2])\n",
    "        loss = loss_criterion(output, y)\n",
    "        # Compute accuracy another way as the output is weights + bias and is continuous\n",
    "        # total_acc.append(accuracy_score(output.detach().numpy(),y.detach().numpy()))\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        temp_L.append(loss)\n",
    "\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "\n",
    "        #\n",
    "        # !!!!\n",
    "        #\n",
    "\n",
    "        \"\"\"        _, predicted = torch.max(output.data, 1)\n",
    "        total += y.size(0)\n",
    "        correct += (predicted == y).sum().item()\"\"\"\n",
    "\n",
    "        i += 1\n",
    "    total_L.append(sum(temp_L)/float(len(temp_L)))\n",
    "    print(f\"Loss : {total_L[-1]}, epoch({epoch})\")\n",
    "    #print('Accuracy of the network on the train graphs : %d %%' % (100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "L_2 = [T.detach().numpy() for T in total_L]\n",
    "\n",
    "L_2 = np.array(L_2)\n",
    "\n",
    "plt.figure()\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "plt.plot(L_2)\n",
    "plt.title('Evolution of the loss')\n",
    "plt.xlabel('Epoch');plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test graphs : 58 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        X_test, labels = data\n",
    "        X_test, labels = X_test.float(), labels.type(torch.LongTensor)\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = CNN(X_test)\n",
    "\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "print('Accuracy of the network on the test graphs : %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class FNSZ  is: 69.7 %\n",
      "Accuracy for class GNSZ  is: 37.9 %\n"
     ]
    }
   ],
   "source": [
    "# prepare to count predictions for each class\n",
    "classes = ('FNSZ','GNSZ')\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        X_test, labels = data\n",
    "        X_test, labels = X_test.float(), labels.type(torch.LongTensor)\n",
    "        outputs = CNN(X_test)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        #print(outputs.shape)\n",
    "        #print(torch.max(outputs, 1)[1].shape)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname,\n",
    "                                                   accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ca02964d08fc28c71d2bf17a5c1f94340d35561783d4e82c93d82793d6a36248"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
