{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this if using cov matrix (or to keep the adjacency matrix)\n",
    "is_cov = False\n",
    "\n",
    "# Keep data in 2D for 2D convolution of the NN\n",
    "def load_graphs(input_dir, class_dict) :\n",
    "\n",
    "    data, data_labels = [], [] # data containing the graphs and data_labels the associated seizure type labels\n",
    "    i=0\n",
    "    for szr_type in class_dict.keys() :\n",
    "        szr_label = class_dict[szr_type]\n",
    "        for _, _, files in os.walk(os.path.join(input_dir,szr_type)) :\n",
    "            for npy_file in files :\n",
    "                A = np.load(os.path.join(input_dir,szr_type,npy_file))\n",
    "\n",
    "                # Normalise A (already normalised depending on the input)\n",
    "                A = A/np.amax(A.flatten())\n",
    "                if is_cov : \n",
    "                    L = torch.tensor(A).view(1,20,20)\n",
    "                else : \n",
    "                    L = torch.tensor(np.diag(A*np.ones((A.shape[0],1)))-A).view(1,20,20)\n",
    "                    #L = torch.tensor(A).view(1,20,20)\n",
    "\n",
    "                data.append(L)\n",
    "                data_labels.append(szr_label)\n",
    "\n",
    "    return np.array(data), np.array(data_labels)\n",
    "\n",
    "def train_test_data(input_dir, class_dict) :\n",
    "\n",
    "    train, train_labels = load_graphs(os.path.join(input_dir,'train'), class_dict)\n",
    "    test, test_labels = load_graphs(os.path.join(input_dir,'dev'), class_dict)\n",
    "\n",
    "    return train, test, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rapha\\AppData\\Local\\Temp/ipykernel_19060/594653910.py:26: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  return np.array(data), np.array(data_labels)\n",
      "C:\\Users\\rapha\\AppData\\Local\\Temp/ipykernel_19060/594653910.py:26: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(data), np.array(data_labels)\n"
     ]
    }
   ],
   "source": [
    "# Need to put it as a torch.Size([1, 20, 20])\n",
    "input_dir = '../data/v1.5.2/graph_unnormal'\n",
    "#input_dir = '../data/v1.5.2/graph_cov_low'\n",
    "#input_dir = '../data/v1.5.2/graph_avg_1_5'\n",
    "szr_types = ['FNSZ','GNSZ']\n",
    "\n",
    "class_dict = {}\n",
    "for i, szr_type in enumerate(szr_types) :\n",
    "    class_dict[szr_type] = i\n",
    "\n",
    "train, test, train_labels, test_labels = train_test_data(input_dir, class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536  vs  409\n",
      "3\n",
      "309\n"
     ]
    }
   ],
   "source": [
    "# Oversampling (train set only) to have balanced classification without dropping information\n",
    "PD = pd.DataFrame(train_labels,columns=['label'])\n",
    "no_0, no_1 = len(PD[PD['label']==0]), len(PD[PD['label']==1])\n",
    "print(no_0, ' vs ', no_1)\n",
    "\n",
    "R = math.floor(no_0/no_1)\n",
    "print(R) # Multiply the dataset by this ratio, then add (no_0 - R*no_1) randomly selected entries from the smallest dataset\n",
    "print(no_0 - R*no_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "trainset, testset = [], []\n",
    "for i in range(len(train)) :\n",
    "    if train_labels[i] == 1 : # Under-represented class :\n",
    "        # The dataloader later shuffles the data\n",
    "        for r in range(R) :\n",
    "            trainset.append((train[i],train_labels[i]))\n",
    "    else :\n",
    "        trainset.append((train[i],train_labels[i]))\n",
    "\n",
    "# Compensate the remaining imbalance => draw (no_0 - R*no_1) elements from already present elements\n",
    "Add = random.sample(PD[PD['label']==1].index.to_list(),no_0 - R*no_1)\n",
    "for idx in Add :\n",
    "    trainset.append((train[idx],train_labels[idx]))\n",
    "\n",
    "for j in range(len(test)) :\n",
    "    testset.append((test[j],test_labels[j]))\n",
    "classes = ('FNSZ','GNSZ')\n",
    "\n",
    "#trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "#testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536  vs  1536\n"
     ]
    }
   ],
   "source": [
    "len(trainset)\n",
    "tmp_set = []\n",
    "for s in trainset :\n",
    "    tmp_set.append(s[1])\n",
    "\n",
    "PD_tmp = pd.DataFrame(tmp_set,columns=['label'])\n",
    "tmp_0, tmp_1 = len(PD_tmp[PD_tmp['label']==0]), len(PD_tmp[PD_tmp['label']==1])\n",
    "print(tmp_0, ' vs ', tmp_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.fc1 = nn.Linear(16 * 3 * 3, 80)\n",
    "        self.fc2 = nn.Linear(80, 40)\n",
    "        self.fc3 = nn.Linear(40, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nclass Net_2(nn.Module):\\n    def __init__(self):\\n        super().__init__()\\n        self.conv1 = nn.Conv2d(3, 6, 5)\\n        self.pool = nn.MaxPool2d(2, 2)\\n        self.conv2 = nn.Conv2d(6, 16, 5)\\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\\n        self.fc2 = nn.Linear(120, 84)\\n        self.fc3 = nn.Linear(84, 10)\\n\\n    def forward(self, x):\\n        x = self.pool(F.relu(self.conv1(x)))\\n        x = self.pool(F.relu(self.conv2(x)))\\n        print('Before : ',x.shape)\\n        x = torch.flatten(x, 1) # flatten all dimensions except batch\\n        print('After : ',x.shape)\\n        x = F.relu(self.fc1(x))\\n        x = F.relu(self.fc2(x))\\n        x = self.fc3(x)\\n        return x\\n\\nCNN = Net_2()\\nCNN = CNN.float()\\ncriterion = nn.CrossEntropyLoss()\\noptimizer = optim.SGD(CNN.parameters(), lr=0.001, momentum=0.9)\\n\""
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "class Net_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        print('Before : ',x.shape)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        print('After : ',x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "CNN = Net_2()\n",
    "CNN = CNN.float()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(CNN.parameters(), lr=0.001, momentum=0.9)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=144, out_features=80, bias=True)\n",
      "  (fc2): Linear(in_features=80, out_features=40, bias=True)\n",
      "  (fc3): Linear(in_features=40, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Run forward pass once and check flattened output dimensions\n",
    "CNN = Net()\n",
    "CNN = CNN.float()\n",
    "print(CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 1e-4\n",
    "loss_criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(CNN.parameters(), lr=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch_size :  50 \n",
      "Learning rate :  0.0001\n",
      "Epoch : 0, Loss : 0.693594\n",
      "Epoch : 1, Loss : 0.692251\n",
      "Epoch : 2, Loss : 0.690419\n",
      "Epoch : 3, Loss : 0.685889\n",
      "Epoch : 4, Loss : 0.677099\n",
      "Epoch : 5, Loss : 0.661829\n",
      "Epoch : 6, Loss : 0.643356\n",
      "Epoch : 7, Loss : 0.626734\n",
      "Epoch : 8, Loss : 0.611697\n",
      "Epoch : 9, Loss : 0.603025\n",
      "Epoch : 10, Loss : 0.593427\n",
      "Epoch : 11, Loss : 0.586065\n",
      "Epoch : 12, Loss : 0.582786\n",
      "Epoch : 13, Loss : 0.576218\n",
      "Epoch : 14, Loss : 0.572474\n",
      "Epoch : 15, Loss : 0.56908\n",
      "Epoch : 16, Loss : 0.565468\n",
      "Epoch : 17, Loss : 0.560396\n",
      "Epoch : 18, Loss : 0.559726\n",
      "Epoch : 19, Loss : 0.554732\n",
      "Epoch : 20, Loss : 0.552052\n",
      "Epoch : 21, Loss : 0.548845\n",
      "Epoch : 22, Loss : 0.545382\n",
      "Epoch : 23, Loss : 0.543209\n",
      "Epoch : 24, Loss : 0.540686\n",
      "Epoch : 25, Loss : 0.53674\n",
      "Epoch : 26, Loss : 0.535319\n",
      "Epoch : 27, Loss : 0.532447\n",
      "Epoch : 28, Loss : 0.530586\n",
      "Epoch : 29, Loss : 0.530235\n",
      "Epoch : 30, Loss : 0.527501\n",
      "Epoch : 31, Loss : 0.52459\n",
      "Epoch : 32, Loss : 0.522907\n",
      "Epoch : 33, Loss : 0.521982\n",
      "Epoch : 34, Loss : 0.520139\n",
      "Epoch : 35, Loss : 0.517342\n",
      "Epoch : 36, Loss : 0.515503\n",
      "Epoch : 37, Loss : 0.513636\n",
      "Epoch : 38, Loss : 0.513002\n",
      "Epoch : 39, Loss : 0.511093\n",
      "Epoch : 40, Loss : 0.511037\n",
      "Epoch : 41, Loss : 0.508282\n",
      "Epoch : 42, Loss : 0.507602\n",
      "Epoch : 43, Loss : 0.50541\n",
      "Epoch : 44, Loss : 0.504162\n",
      "Epoch : 45, Loss : 0.504607\n",
      "Epoch : 46, Loss : 0.501508\n",
      "Epoch : 47, Loss : 0.50138\n",
      "Epoch : 48, Loss : 0.500412\n",
      "Epoch : 49, Loss : 0.49892\n",
      "Epoch : 50, Loss : 0.496915\n",
      "Epoch : 51, Loss : 0.49675\n",
      "Epoch : 52, Loss : 0.4946\n",
      "Epoch : 53, Loss : 0.495964\n",
      "Epoch : 54, Loss : 0.492521\n",
      "Epoch : 55, Loss : 0.493023\n",
      "Epoch : 56, Loss : 0.490849\n",
      "Epoch : 57, Loss : 0.489752\n",
      "Epoch : 58, Loss : 0.489385\n",
      "Epoch : 59, Loss : 0.487526\n",
      "Epoch : 60, Loss : 0.487168\n",
      "Epoch : 61, Loss : 0.486104\n",
      "Epoch : 62, Loss : 0.484939\n",
      "Epoch : 63, Loss : 0.482857\n",
      "Epoch : 64, Loss : 0.482753\n",
      "Epoch : 65, Loss : 0.482322\n",
      "Epoch : 66, Loss : 0.480085\n",
      "Epoch : 67, Loss : 0.47841\n",
      "Epoch : 68, Loss : 0.478304\n",
      "Epoch : 69, Loss : 0.47635\n",
      "Epoch : 70, Loss : 0.475855\n",
      "Epoch : 71, Loss : 0.475363\n",
      "Epoch : 72, Loss : 0.473626\n",
      "Epoch : 73, Loss : 0.473373\n",
      "Epoch : 74, Loss : 0.471451\n",
      "Epoch : 75, Loss : 0.471567\n",
      "Epoch : 76, Loss : 0.469163\n",
      "Epoch : 77, Loss : 0.468667\n",
      "Epoch : 78, Loss : 0.468509\n",
      "Epoch : 79, Loss : 0.464655\n",
      "Epoch : 80, Loss : 0.465685\n",
      "Epoch : 81, Loss : 0.462941\n",
      "Epoch : 82, Loss : 0.463574\n",
      "Epoch : 83, Loss : 0.461695\n",
      "Epoch : 84, Loss : 0.460263\n",
      "Epoch : 85, Loss : 0.459232\n",
      "Epoch : 86, Loss : 0.45829\n",
      "Epoch : 87, Loss : 0.458197\n",
      "Epoch : 88, Loss : 0.456162\n",
      "Epoch : 89, Loss : 0.456441\n",
      "Epoch : 90, Loss : 0.455495\n",
      "Epoch : 91, Loss : 0.454721\n",
      "Epoch : 92, Loss : 0.451199\n",
      "Epoch : 93, Loss : 0.451332\n",
      "Epoch : 94, Loss : 0.451441\n",
      "Epoch : 95, Loss : 0.449708\n",
      "Epoch : 96, Loss : 0.448892\n",
      "Epoch : 97, Loss : 0.447679\n",
      "Epoch : 98, Loss : 0.448162\n",
      "Epoch : 99, Loss : 0.446736\n"
     ]
    }
   ],
   "source": [
    "total_L, total_acc = [], []\n",
    "print('Batch_size : ',batch_size,'\\nLearning rate : ',gamma)\n",
    "for epoch in range(100): \n",
    "    i = 0\n",
    "    temp_L = []\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in trainloader:\n",
    "        X, y = data\n",
    "        optimizer.zero_grad()\n",
    "        X, y = X.float(), y.type(torch.LongTensor)\n",
    "        output = CNN(X)\n",
    "\n",
    "        loss = loss_criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        temp_L.append(loss)\n",
    "\n",
    "        i += 1\n",
    "    total_L.append(sum(temp_L)/float(len(temp_L)))\n",
    "    print(f\"Epoch : {epoch}, Loss : {round(total_L[-1].item(),6)}\")\n",
    "    #print('Accuracy of the network on the train graphs : %d %%' % (100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEXCAYAAACzhgONAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA1RUlEQVR4nO3deViVdf7/8edZ2XcOi6C44IICimkq7pVLiktmZppLljNajRPNWOTYWOaUmaVdZf5smZnmqznauGLGWFlpQiquoJErAi6sosh6Duf+/WGdiVQS5HDgnPfjurwu7vW834C8zr2cz61SFEVBCCGEuAW1rQsQQgjRtElQCCGEqJUEhRBCiFpJUAghhKiVBIUQQohaSVAIIYSolQSFaLI6duzIqFGjGDNmTI1/OTk59dpfQkICH3300W+uN2PGDIqKigCYOXMmp06dqtfr1cXGjRsZNGgQjz/+eK313HPPPaSlpdX7dXJycoiJian39sIxaW1dgBC1+fjjj/H19W3U19yzZ4/l6w8++KBRXnPz5s3Ex8czZsyYWusRwhbkiEI0S3/605/4+9//bpn+5JNPeOaZZwBYt24dcXFxjB49mhkzZnD27Nkbtu/YsaPlXfovp1944QUApk2bxsWLF2u8g7/VfhMSEli0aBFTpkxhyJAhPP3005SWlt7wmiUlJfz5z38mLi6OUaNGsWTJEkwmE6+++ippaWm8/fbb/POf/6yxza/r+bmOcePGMWjQIJYtW2ZZd+fOnTz00EOMHTuWiRMncujQoVq/h0ajkVdeeYURI0YwatQo/vKXv3Dt2jXL93P06NE8+OCDTJo0yXJUdav5ws4pQjRRHTp0UOLi4pTRo0db/j355JOKoihKSkqKEhcXZ1l3/Pjxyp49e5Tk5GTlvvvuUwoLCxVFUZQNGzYo999/v2I2m5Xnn39e+fDDDy37/nmdX0//8uvBgwcrR48e/c39Pvzww0plZaVSVVWljB07VvnPf/5zQz/PPfec8sorryhms1mprKxUZsyYoaxatUpRFEV59NFHlc8///yW34df1rNw4UJFURQlLy9PiYyMVC5cuKCcPXtWiYuLU4qKihRFUZQTJ04offv2VUpLS2vsKzs7W+nWrZuiKIry9ttvK08//bRSVVWlVFdXKwkJCcqLL76omEwmpUuXLkpubq6iKIqyadMm5d///vct5wv7J6eeRJN2q1NPvXr1orKykrS0NFxcXCgqKqJPnz688cYbjBgxwrLNuHHj+Nvf/lbv6xo/2717d6377d+/P3q9HoAOHTpw5cqVG/axa9cu1q5di0qlQq/XM3HiRD7++GN+97vf1amWuLg4AAwGA/7+/hQWFnLkyBHy8vKYPn26ZT2VSkVWVhadOnW66X527dpFfHw8Op0OgClTpvDUU0+h0WgYPnw4EydOZNCgQfTr14+BAwfecr6wfxIUollSqVSMHz+eLVu2oNPpGD9+PCqVCrPZfMO6iqJgMpluua+qqqrffL3f2q+zs3ON2pSbDKFmNptRqVQ1pmur61a02v/9t/35tcxmM3369GH58uWWZRcvXiQgIOCW+7lZPUajEYClS5dy4sQJkpOTef/999myZQtvv/32LecL+ybXKESz9cADD7Bz507++9//Mm7cOOD6O/vt27dbrj9s2LABb29vwsLCamzr6+trufawbdu2Gss0Gs0Nf8Bvd7+16devH6tXr0ZRFKqqqli/fj2xsbG/ud3N6vm1Pn36sGfPHk6fPg3At99+y+jRo6moqLjlNv3792ft2rUYjUbMZjNr1qyhb9++FBUVMXDgQLy9vZk+fTrPPPMMaWlpt5wv7J8cUYgmbdq0aajVNd/PPPvsswwcOBCDwUDnzp0xmUwEBgYC0LdvX6ZPn860adMwm834+vqyatWqG/Yxf/58Fi5ciKenJ7GxsRgMBsuy4cOHM2XKFN555x3LvNvdb23mz5/PokWLGDVqFEajkf79+zNr1qzf3O5m9fxaeHg4Cxcu5Nlnn0VRFLRaLStXrsTNze2W28yePZvXX3+dsWPHYjKZiI6O5sUXX8TT05PZs2czffp0nJ2d0Wg0LFq0CF9f35vOF/ZPpdzsGFkIIYT4iZx6EkIIUSsJCiGEELWSoBBCCFErCQohhBC1kqAQQghRKwkKIYQQtbLq5ygSExNZuXIlJpOJadOmMXnyZMuyH374gYSEBMt0UVERXl5ebNu2jQsXLjB37lwKCwtp06YNS5curfV+8F+7fLkUs7nud/36+blTWHitzts1d47YtyP2DI7ZtyP2DHXrW61W4eNz67+xVguK3Nxcli1bxsaNGy3j2vTq1Yvw8HAAIiIi2LJlCwDl5eU89NBDvPTSSwC8/PLLTJo0iZEjR7JixQree+895s6de9uvbTYr9QqKn7d1RI7YtyP2DI7ZtyP2DA3Xt9VOPSUnJ9O7d2+8vb1xdXVl2LBhJCUl3XTdVatW0bNnT3r06IHRaGT//v0MGzYMuD742q22E0IIYX1WO6LIy8urMSxCQEAAR48evWG9kpIS1q9fT2JiIgCXL1/G3d3dMvCZwWAgNzfXWmUKIYT4DVYLil+PTKkoSo3pn23dupX77rsPPz+/W653s+1q4+fnXo+KrzMYPOq9bXPmiH07Ys/gmH07Ys/QcH1bLSiCgoJITU21TOfn5990yOMvv/yS3//+95ZpX19fSkpKqK6uRqPR3HK72hQWXqvXuTmDwYP8/JI6b9fcOWLfjtgzOGbfjtgz1K1vtVpV6xtsq12jiI2NJSUlhaKiIsrLy9mxYwcDBgyosY6iKBw7dqzGw951Oh09evRg+/btwPVnCf96OyGEEI3HakERGBhIfHw8U6dOZezYscTFxREdHc3MmTMtY9gXFRWh0+lwcnKqse2CBQtYv349I0aMIDU11fIsZCGEEI3PLocZr8+pp5z8a7y1/gjtgj3p1TmQ6HZ+6HUaK1XYtDjiobkj9gyO2bcj9gwNe+pJHlz0k0AfFwbEhPDNgRwOnMjHxUnDoG4hDO3ZEi93p9/egRBC2CkJip/otBpmjoliVO9WZGQVs/vIBZL2ZfHlgRz6Rwfz4MB2uDjJt0sI4XjkL9+vaNRqurT2pUtrXx7oX8b278/xzaEL5F4u55mHotHU4dGXQghhD+SvXi0CfV15bEQEU4Z14NjZItZ+edLWJQkhRKOTI4rbMLBbCLlF5STtyyLI15X7erS0dUlCCNFo5IjiNo0f1I6Y9v6s/eokJ7KLbV2OEEI0GgmK26RWq/jdqC54uurZlpJp63KEEKLRSFDUgZNewz3dQ0g/U8TFwlJblyOEEI1CgqKOBsaEoNWo+TI1x9alCCFEo5CgqCNPVz29uwSyJ/0i18qNti5HCCGsToKiHob0aEmV0czuIxdsXYoQQlidBEU9tAxwJyLMhy8P5GCqNtu6HCGEsCoJinoa0qMll0sqOXyywNalCCGEVUlQ1FN0uB/uLjqOnJKgEELYNwmKelKrVHRs5U1GVrGtSxFCCKuSoLgDnVr5UHi1goLicluXIoQQViNBcQc6tfIG4Iesy7YtRAghrEiC4g608HfDw1XHj3L6SQhhxyQo7oBKpaJjKx8ysi5jh0+UFUIIQILijnVq5U3R1Uryr1TYuhQhhLAKCYo71LGVDwA/npPrFEII+yRBcYda+Lni6aojQy5oCyHslATFHfrfdYpiuU4hhLBLEhQNoFMrby6XVJIvn6cQQtghCYoG0Cns+nUK+ZS2EMIeSVA0gCBfVzxcdZzMKbZ1KUII0eAkKBqASqWiTbAnmRdLbF2KEEI0OAmKBtIm2JMLBaWUV5psXYoQQjQoCYoG0ibYAwXIypWjCiGEfZGgaCCtgz0BOCunn4QQdkaCooF4uurx83Tm7MWrti5FCCEalFWDIjExkREjRjB06FDWrFlzw/IzZ84wZcoURo8ezeOPP86VK1cA2LRpE/369WPMmDGMGTOGZcuWWbPMBtOmhacEhRDC7lgtKHJzc1m2bBmffPIJmzdvZt26dZw6dcqyXFEUZs+ezcyZM9m6dSsRERG8//77AKSnp5OQkMCWLVvYsmUL8fHx1iqzQbUJ9qDgSgVXy6psXYoQQjQYqwVFcnIyvXv3xtvbG1dXV4YNG0ZSUpJl+bFjx3B1dWXAgAEAzJo1i8mTJwOQlpbGpk2bGDVqFH/+858tRxpNXZug69cp5DZZIYQ9sVpQ5OXlYTAYLNMBAQHk5uZaprOysvD392fevHk88MADLFiwAFdXVwAMBgNPPvkkW7duJTg4mIULF1qrzAYVFuSBCsiU009CCDuitdaOzWYzKpXKMq0oSo1pk8nEvn37WL16NVFRUSxfvpzFixezePFiVqxYYVnviSeeYMiQIXV6bT8/93rXbTB41HtbgNBAD84Xld3xfhpbc6u3IThiz+CYfTtiz9BwfVstKIKCgkhNTbVM5+fnExAQYJk2GAyEhYURFRUFQFxcHHPmzKGkpIQNGzYwffp04HrAaDSaOr12YeE1zOa6j+RqMHiQn39np41aGdxIO1NIXt7VGsHYlDVE382NI/YMjtm3I/YMdetbrVbV+gbbaqeeYmNjSUlJoaioiPLycnbs2GG5HgEQExNDUVERGRkZAOzcuZMuXbrg6urKhx9+yJEjRwBYvXp1nY8obKl1sCdXy4wUXa20dSlCCNEgrHZEERgYSHx8PFOnTsVoNDJ+/Hiio6OZOXMmc+bMISoqihUrVjB//nzKy8sJCgpiyZIlaDQali9fzksvvURFRQWtW7dmyZIl1iqzwbWxfPDuKn5ezjauRggh7pxKscOn7djy1JPRZObJt75laM+WPDQ4/I721Vgc8dDcEXsGx+zbEXuGZnLqyVHptGpaBXpw+nzzuKVXCCF+iwSFFbQP9eLspRJM1WZblyKEEHdMgsIKwkO8MJrMnLvkeIe7Qgj7I0FhBe1DvQA4mSOnn4QQzZ8EhRV4uTth8HbmlFynEELYAQkKKwkP8eZUTjF2eFOZEMLBSFBYSfuWXlwtM5JXXG7rUoQQ4o5IUFhJ+5Dr1ylOyXUKIUQzJ0FhJcH+brg6aTmZU2zrUoQQ4o5IUFiJWqUiPNRL7nwSQjR7EhRWFB7ixcXCMq6VG21dihBC1JsEhRX9/HkKuU1WCNGcSVBYUetgTzRqlVzQFkI0axIUVuSk0xAW5MGJ7GJblyKEEPUmQWFlnVr5cPbiVSqqTLYuRQgh6kWCwso6hXlTbVbk9JMQotmSoLCy9iHeaNQqfjh32dalCCFEvUhQWJmTXkPbFp5kZElQCCGaJwmKRtCplQ+Zl0ooq5DrFEKI5keCohFEhPmgKMjdT0KIZkmCohG0C/FEq1HL6SchRLMkQdEIdFoN4SGeZMgFbSFEMyRB0UgiwnzIzrsm4z4JIZodCYpG0inMBwX4UU4/CSGaGQmKRtIm2BO9Tk3GuWJblyKEEHUiQdFItBo1Ea18OHgyH1O12dblCCHEbZOgaESDu4dwuaSS1Iw8W5cihBC3TYKiEUW29SPI15Ud+7NRFMXW5QghxG2RoGhEapWKoT1bknmpRB6RKoRoNiQoGlmfyCDcnLXs2J9t61KEEOK2SFA0MiedhkExIRw6kU/e5TJblyOEEL/JqkGRmJjIiBEjGDp0KGvWrLlh+ZkzZ5gyZQqjR4/m8ccf58qV66djLly4wOTJkxk+fDizZ8+mtLTUmmU2unu6h6JWq/gyNcfWpQghxG+yWlDk5uaybNkyPvnkEzZv3sy6des4deqUZbmiKMyePZuZM2eydetWIiIieP/99wF4+eWXmTRpEklJSURGRvLee+9Zq0yb8PFw4u6IAL5Lu0hlVbWtyxFCiFpZLSiSk5Pp3bs33t7euLq6MmzYMJKSkizLjx07hqurKwMGDABg1qxZTJ48GaPRyP79+xk2bBgA48aNq7GdvRgUE0JFVTV7f8i1dSlCCFErqwVFXl4eBoPBMh0QEEBu7v/+KGZlZeHv78+8efN44IEHWLBgAa6urly+fBl3d3e0Wi0ABoOhxnb2IjzEixb+bnx7+IKtSxFCiFpprbVjs9mMSqWyTCuKUmPaZDKxb98+Vq9eTVRUFMuXL2fx4sXEx8fXWA+4Yfq3+Pm517tug8Gj3tvW1ch+bfhgczolVWbahng12uveTGP23VQ4Ys/gmH07Ys/QcH1bLSiCgoJITU21TOfn5xMQEGCZNhgMhIWFERUVBUBcXBxz5szB19eXkpISqqur0Wg0N2x3OwoLr2E21/0DbQaDB/n5JXXerr6iW/ug06rZ/PVJpgzr2Giv+2uN3XdT4Ig9g2P27Yg9Q936VqtVtb7Bttqpp9jYWFJSUigqKqK8vJwdO3ZYrkcAxMTEUFRUREZGBgA7d+6kS5cu6HQ6evTowfbt2wHYvHlzje3siZuzjp6dAkg5dkkuagshmiyrBUVgYCDx8fFMnTqVsWPHEhcXR3R0NDNnziQtLQ1nZ2dWrFjB/PnzGTlyJHv37iUhIQGABQsWsH79ekaMGEFqairPPPOMtcq0uYHdWshFbSFEk6ZS7HDQoeZy6gmuX7t58aN96LRq/jqtR52vxzQERzw0d8SewTH7dsSeoZmcehK3R6VScV+PUM5dKuHo6UJblyOEEDeQoGgC+kUFY/B2ZtOuM5jt7wBPCNHMSVA0AVqNmrH92pKVd02eVSGEaHIkKJqIXp0DaeHvxqbdZ6k2yxPwhBBNhwRFE6FWq3igf1tyi8pITr9k63KEEMJCgqIJ6d7Bn9ZBHmzadYZcGYJcCNFESFA0ISqViqnDO2KqVvjbvw5wIrvY1iUJIYQERVPTOsiTv0y9CzcXHUv/fYiUY3IaSghhWxIUTVCgjyt/mXIX4SFefJh4nLMXr9q6JCGEA7utoCgoKOCrr74C4I033mDatGmWMZqEdbi76PjDg9F4uOn55MsT8vkKIYTN3FZQJCQkkJ2dTUpKCrt372bMmDEsWrTI2rU5PBcnLeMHtuP0+at8L6eghBA2cltBUVxczPTp09m1axdxcXGMGzeO8vJya9cmgNioINoEe/LpN6cprzTZuhwhhAO6raAwGo0YjUZ2795NbGws5eXllJXJ7ZuNQa1SMWlIe65cq2JbSqatyxFCOKDbCop7772XPn364OPjQ2RkJA899BBxcXHWrk38pF0LL/pGBbFjXzbHMotsXY4QwsHc9jDjly5dIjAwEJVKRUZGBp06dbJ2bfXWnIYZv13Xyo0s+eQguZfLeXpcFFFt/Rps3025b2txxJ7BMft2xJ7BBsOMFxQUcOzYMVQqFW+88Qavvfaa3PXUyNxddDw3qTvBfq68s+Eoh08W2LokIYSDkLuemhF3Fx1zH4mhZYA7KzalyYfxhBCNQu56ambcnHX86eEY2od68UHicT5LycQOH1IohGhC5K6nZsjVWUv8hG7cHRHAhm/PsHrHiXpdkxFCiNuhvZ2Vfr7rKSIigsjISOLi4uSuJxvTadX8bnQXfD2dSdqbxbVyIzNHdUarkVFZhBAN67aCYs6cOUyYMIGgoCAAli5d2qTvenIUapWKCYPD8XTVs/7rU1RUVfPkA5E46TS2Lk0IYUduKyjMZjOJiYns2rULk8lE3759CQ8PR6u9rc2FlQ3v1QoXJw3/SvqRZeuP8Mfx0bg4yc9GCNEwbus8xZtvvsn333/PtGnTeOyxxzh06BBLliyxdm2iDgZ2C+H3Y7pwKucK/9j+g1zgFkI0mNt627l79242bNiATqcDYNCgQYwePZp58+ZZtThRN3dHBFJ4tYJPvz7NVwdyuK9HS1uXJISwA7d1RKEoiiUkAPR6fY1p0XQMu7sV3cL9WbfzFGcuyHMshBB37raColOnTrz66qtkZWWRnZ3Na6+9RocOHaxdm6gHtUrFjJEReLs7sXJzOqfOX5FRZ4UQd+S2gmLBggVcvXqViRMnMmHCBAoLC3nkkUesXZuoJ3cXHbPHRnKltIpX/+8ATy3bxXMrk0nNyLN1aUKIZui2rlG4u7uzePHiGvO6d+/OwYMHrVKUuHNtW3iyZHYfzl68Sk5+KakZeXy47ThBvq6EBtx68C8hhPi1en86S+6qafq83Z2IaW9gVGxrnp3QFRdnLSs2pcmpKCFEndQ7KFQqVUPWIazMy92J2WMiyS+u4O9y+6wQog5kvAcH0qGlN+MHtePAj/ms//oUpmqzrUsSQjQDtV6jiImJuemRg6IoVFRU/ObOExMTWblyJSaTiWnTpjF58uQay9999102bNiAp6cnABMmTGDy5Mls2rSJN998Ez+/6w/nGTRoEPHx8bfdlLi1YXe3JO9yGf/dl82PWcXMHNUZg8HD1mUJIZqwWoNi27Zt9d5xbm4uy5YtY+PGjej1eiZOnEivXr0IDw+3rJOens5bb71FTExMjW3T09NJSEiQgQetQKVSMXV4Jzq39uVf//2Rl/+xn989EE33dr62Lk0I0UTVGhQhISH13nFycjK9e/fG29sbgGHDhpGUlMTTTz9tWSc9PZ1Vq1Zx/vx5evbsyfPPP4+TkxNpaWlkZmayatUqOnbsyIsvvoiXl1e9axE36tEpgPBQLz7adpx3Pz3MfT1CefiecDRqORsphKjJan8V8vLyMBgMlumAgAByc3Mt06WlpURERDB37lw2bdrE1atXee+99wAwGAw8+eSTbN26leDgYBYuXGitMh2at7sT8RO6MXpAW75MzeHt/xylrELuiBJC1KRSrHT7y8qVK6msrOSZZ54BYP369aSnp9/yj/7x48eZN28emzdvrjH/ypUrDBkyhH379lmjTPGTpJRM/t/Go4QEuPPyzD74e7vYuiQhRBNhtbGog4KCSE1NtUzn5+cTEBBgmb5w4QLJycmMHz8euH6BXKvVUlJSwoYNG5g+fbplvkZTt+crFBZeq9cT3wwGD/LzS+q8XXNnMHhwV7gf8RO68u7GNP709rc8O6EbLfzdbF2a1Tjyz9rR+nbEnqFufavVKvz8bv1BXKudeoqNjSUlJYWioiLKy8vZsWMHAwYMsCx3dnbmjTfeIDs7G0VRWLNmDUOGDMHV1ZUPP/yQI0eOALB69WqGDBlirTLFL3Ru7cvzk7pjqlZ4bfUBTmQX27okIUQTYLWgCAwMJD4+nqlTpzJ27Fji4uKIjo5m5syZpKWl4evry8KFC5k9ezbDhw9HURQee+wxNBoNy5cv56WXXuL+++/n2LFjzJ0711plil8JC/Jg3pS7cHPR8fqag3z02XEul1TauiwhhA1Z7RqFLcmpp7q5Wd9lFSa2pWTyZWo2arWKkX1ac3+vVnbzTG75WTsOR+wZmsmpJ9G8uTprmTA4nEVP9CKqjR+bdp3hlY9TOXfJ8f7DCeHoJChErQJ8XHlqXBR/GBfF1bIqXvk4lc27z8hYUUI4EKvd9STsS0wHAx1aefPJFyfZuieTiqpqHr4nXAaHFMIBSFCI2+bmrOOJuAjcXLTs2J+NVqPmwYFtJSyEsHMSFKJOVCoVj9zbHlO1wvbvz6GgENenNS5O8qskhL2S/92izlQqFY8O7UB1tZnPv8/iqwM53NUhgAFdg+nYysfW5QkhGpgEhagXtUrF9Ps70T+6BXvSL7LvhzxSjl1iULcWTLy3PXpd3T5NL4RouiQoRL2pVCrCQ70ID/XikXvbs2XPWT7/PovTF64ye2wkQb6uti5RCNEA5PZY0SD0Og0PDQrnmYeiuVxSycv/2M+n35ziammVrUsTQtwhOaIQDSq6nT8vPdaT9V+fIun7LL5KzaFvdDBhgR54uurx8XCiVaC73CklRDMiQSEanK+nM7PGRDKmXynbvz/HrsMXqP7FkCrR7fx4bEQEXm56G1YphLhdEhTCaoL93Hh8ZGemDuvE1dIqrpZV8WNWMZt2n2HBR3uZMTKC6Hb+ti5TCPEb5BqFsDqdVo2flzNtgj0Z3qsVf53WA083Pcs/Pcq/vzqJqdps6xKFELWQoBCNLsTgzovTenBv91B27M/m9TUHKbxSYeuyhBC3IEEhbEKn1TB5aAdmj43kfEEpL/1jH18fzKGyqtrWpQkhfkWuUQib6tkpgFYB7ny47Tj/t+MEG3edYUC3FvSKCCQ0wB213B0lhM1JUAibC/R1Zd6UuziZc4UvUrNJ2pvF599n4eqkpX2oFz06BdCrc6DdPDRJiOZGgkI0CSqVig4tvenQ0pvLJZX8cK6IE9nFZJwr5qPPfmDz7rPc37sV/aOD0WlleBAhGpMEhWhyfDyciI0MJjYyGEVROHK6kM+SM1m94wRfpOYwa3QXwoI8bF2mEA5DjuVFk6ZSqegW7s+8KXcRP6ErlVUm/vZ/qXyxP1uesidEI5GgEM2CSqUiqq0fL8+4my6tfVn71UneWHuIjHOXJTCEsDIJCtGseLjqmTM+milDO3ChsIwlaw/x2uqDHD1dIIEhhJXINQrR7KhUKgZ3D6VvVDC7j14kae85ln96lLBAD+JiWxPTwV9uqxWiAUlQiGZLr9Nw712hDOzWgpT0S3yWco4Vm9Lw9XSiVYAHwf6utA32pFt7fzRqOXgWor4kKESzp9Wo6d+1BbFRQez/IY9DJwu4UFhK2plCqs0KgT4uxMW2pneXQAkMIepBgkLYDY1aTe8uQfTuEgRAtdnM4ZMFbN2TyUef/cC6nadwddaiUavw9nDmgf5tCA/xsnHVQjR9EhTCbmnUau7qGEBMBwOHTxZw6EQ+JrOC2ayQmVvC4tUHGdOvNSP7tEatlmsaQtyKBIWwe2qViu4dDHTvYLDMc3V3ZvknB9i0+yxpZ4ro3sFAaIAbLQM85IFKQvyKBIVwSG4uOn43ugtRbf34z7enWf/1Kcuy3l0CGT+wHb6ezjasUIimQ4JCOLQ+kUH0iQyipKyKnPxS0s8U8kVqDgd/zGd4r1bc0z0UTznCEA5OgkIIrn+QLyJMT0SYD4NjQvj0m9Ns3ZNJYnImHVt6E9PegFqtouhqBVdKq7g7IkAe4yochlWDIjExkZUrV2IymZg2bRqTJ0+usfzdd99lw4YNeHp6AjBhwgQmT57MhQsXmDt3LoWFhbRp04alS5fi5uZmzVKFsPD3dmH22EhG5V1jX0YeB37MY+1XJwHQalQ46TQkp19ibL82xPVtLR/uE3bPakGRm5vLsmXL2LhxI3q9nokTJ9KrVy/Cw8Mt66Snp/PWW28RExNTY9uXX36ZSZMmMXLkSFasWMF7773H3LlzrVWqEDcVGuBOaIA74wa0peBKOTqtBg9XHSaTmY+TfmTzd2fJyrvGmH5t0OvU6H9aLs/NEPbGakGRnJxM79698fb2BmDYsGEkJSXx9NNPW9ZJT09n1apVnD9/np49e/L888+jVqvZv38/K1asAGDcuHE8+uijEhTCpvy9XCxf63UanoiLICzQnXVfn+LgiXzLMie9hvahXnRq5UN0Oz9CDe62KFeIBmW1oMjLy8Ng+N/tiAEBARw9etQyXVpaSkREBHPnziUsLIyEhATee+89Jk+ejLu7O1rt9dIMBgO5ubnWKlOIelGpVAy9uxWd2/hyqbCMKlM1VUYz2fnX+DGrmP98c5r/fHOaNsGe9O8aTK+IQFyc5JKgaJ6s9ptrNptR/eLcraIoNabd3Nz44IMPLNMzZsxg3rx5TJo0qcZ6wA3Tv8XPr/7v4gwGx3wgjiP23RA932ofl69WsOvweXbsPce/kn5k47dnGDc4nFH92uJs48CQn7XjaKi+rfYbGxQURGpqqmU6Pz+fgIAAy/SFCxdITk5m/PjxwPUg0Wq1+Pr6UlJSQnV1NRqN5obtbkdh4TXM5roPOW0weJCfX1Ln7Zo7R+y7MXqOjQigTycDZy5cJTE5k39t/4HN356mb1QQ7s469DoNAT4uRLbxrfObofqSn7XjqEvfarWq1jfYVrvqFhsbS0pKCkVFRZSXl7Njxw4GDBhgWe7s7Mwbb7xBdvb1J5WtWbOGIUOGoNPp6NGjB9u3bwdg8+bNNbYTojlRqVS0C/HimYe6Mu/Ru2jh58rn32fx6TenWfPFCZatP8Jrqw9y+vwVAHKLyti8+wwfbTtO0dUKG1cvxHUqxYpPe0lMTGTVqlUYjUbGjx/PzJkzmTlzJnPmzCEqKor//ve/vPPOOxiNRrp3787LL7+MXq/n/PnzJCQkUFhYSHBwMG+99RZeXrc/eJscUdSNI/Zty57NioLRaKbSWM3hUwVs2nWGK6VVBPm6cqmoDBWg0ajxdNMRP6EbIf4Nd2u4/KwdR0MeUVg1KGxFgqJuHLHvptRzRZWJz7/P4mROMdHt/Lk7IoBr5UaWrT+CqdrMUw9E4ePhRH5xOdcqjHRt51/vC+NNqe/G4og9Q8MGhdyGIYSNOeu1PDCgbY15vp7OzJtyF2+tO8yStYdqLPNy0/PAgLb0iwqWUW9Fo5CgEKKJMni7MG/KXaSkX8LNRYfB24Vqs8LGXaf55+cZfHUgh37RwUS39SPQ19XW5Qo7JkEhRBPm4apn6N2tasyb9+hd7M/IY8t3Z1n75UnWchKDtzPBfm54uenxdncipoM/rYM8bVS1sDcSFEI0MyqVirsjArk7IpC84nLSThdyPLOIwqsVnLtUwtWyKhKTM4ls68uo2Na0D/W2dcmimZOgEKIZC/B24d67Qrn3rlDLvPJKEzsP5vDffdm8tvogLk5avNz0eLnpaR/mQ7sgDzq18sFJr7Fh5aI5kaAQws64OGkZ2ac1993VkuRjl7hQUMqV0iqKr1WyY28WVcZqtBoVHVt60629ga7hfjXGshLi1yQohLBTTnoNg2NCaszz8nYl+VAO6WcLOXq6kDVfnGDNF9A+1Ivxg9rJaSpxUxIUQjgQvU5Dlza+dGnjy8P3tCe3qIyDJ/P5Yv/101Tdwv25p3sIzk5adBo1zk4afNyd0OvkNJUjk6AQwoEF+rpyf68w7ukeyhf7s/l87zkOnyq4YT13Fx2hBjfGDWhHeOjtj5Ig7IMEhRACJ52GuNjWDIoJITvvGqZqMyaTmbJKE5dLKikqqeTIqQJeXX2A3l0CeWhQOD4eTrYuWzQSCQohhIW7i46IMJ+bLqsY3I7t358jaW82B3/Mp09kEPf1aNmgY1GJpkmCQghxW5z1WsYNaEe/6BZsT8kkOf0S3x6+QPtQLzzd9Og0alyctQzs2oJWgY75/Ad7JUEhhKiTAG8Xpt8fwYMD2/Ht4QscPJHPhYJSTNVmrpYa+frgee7qYGBMvzaEBsijYO2BBIUQol48XPXExbYmLra1ZV5ZhZEd+7P5IjWbAyfycXXS4u/tjMHLBX9vZ/y9XDB4O9OxpXzgrzmRoBBCNBhXZx1j+7flvh4tSTl2iUtFZRQUV3ChsJSjZwoxmswAuDlrGdw9hHu7h+LlLhfFmzoJCiFEg3N30TGkR8sa88yKQklpFTkFpXxz8DyfJZ8jaW8Wgb6uuDlpcXPR0bm1LwO6BqPTytFGUyJBIYRoFGqVCi93J7zcnejS2pfcy2V8c+g8eZfLKaswcbGwjEMnC/gsJZMRvcOIbOuHyWTGWG3G4O2Cu4vO1i04LAkKIYRNBPq48vA97WvMyzh3mc3fneWTL08CJy3zXZw0jB/YjoExIahV8rCmxiZBIYRoMjqF+fB8K29Onb9CwZUKdBo1arWKrw7k8H87TpCcfokx/dsQ7OuGj4eTPOGvkUhQCCGaFJVKRftQb9r/b+R0Ytr78/2xXNZ+dZK31h0BQKNW4emmx0mnwUmnIcTgxqNDO+Cslz9rDU2+o0KIJk+lUtEnMoiu4f6cvXiV/CvlFBRXcKW0kiqjmUpjNSnHLlFwpYL4h7rKrbcNTIJCCNFsuDpr6dLG96bL9h7P5f3EYyz/9AjPPNQVs6LwY1YxppMFRLX2wUlGwK03CQohhF3o1TkQBYUPEo/zwvspXC01YlYUAIL9XPn96C4ytEg9SVAIIexG785BaNRqdh0+T98oTzq39sXN3Yllaw+y6F+pjOgdhkql4kJBKcXXKrk7IlA+t3EbVIryU+TakcLCa5jNdW/LYPAgP7/EChU1bY7YtyP2DI7Zt8HgwZlzhfxjewaHTxWgAgzeLjjpNWTnXcPLXc/9d7eiX3QLXJ3t571zXX7WarUKP79bj8tlP98VIYS4BQ9XPX94MIqCKxV4uenR6zQoP13D2LrnLP/eeYoNu84Q096fvlHBRIT5oNWobV12kyFBIYRwCCqVCoO3S43pTmE+dArz4ezFq+xJu8je47ns+yEPJ72Gji296dLal05hPoQY3Bz6g34SFEIIh9cm2JM2wZ48fE970s8Ukn62iGOZRRw9XQhcH8SwQ0tvfD2d0WpUaDVqOrT0JrKNLyoHCBAJCiGE+IlOqyamg4GYDgYACq6U82NWMT9mF3Myu5gT2cWYqhWMJjOfpZyjQ6gXDw5qR/tQb8yKQlmFCb1Wjd7ObsWVoBBCiFvw93LBP8qFvlHBNeabqs3sPnKBrXsyeW31QdyctZRVmFC4/onxNsGedGzlTftQL1oHeeLpprdNAw1EgkIIIepIq1EzuHsosZHBfH3oPPlXynF31uHmouNKaSUnsopJ2pvFZynX77708XAiup0fj9zbvlkebVg1KBITE1m5ciUmk4lp06YxefLkm673zTffsHDhQnbu3AnApk2bePPNN/Hz8wNg0KBBxMfHW7NUIYSoMye9huG9Wt10WUWViXOXSsi8VMLZi1fZdfgCFwpK+eP4aFydm9eQ6VYLitzcXJYtW8bGjRvR6/VMnDiRXr16ER4eXmO9goICXn/99Rrz0tPTSUhIIC4uzlrlCSGEVTnrtXRs5UPHVj4AdO+QyweJx1m85hDPPtwVb3cnFEWh2nz9moep2oxGrWqSIWK1oEhOTqZ37954e3sDMGzYMJKSknj66adrrDd//nyefvpp3nzzTcu8tLQ0MjMzWbVqFR07duTFF1/Ey8vLWqUKIYTV3R0RiKuzlhUb03n+/6WgVqmoMlXzy488q4Bu7f0Z3qsV4SFeTeaOKqsFRV5eHgaDwTIdEBDA0aNHa6zzr3/9i86dO9O1a9ca8w0GAzNmzKB79+689dZbLFy4sEaQCCFEcxTZxo+Eyd35Lu0iGrUKvU6NTqtBp1Gj06q5XFLJt4fPc+hkAW2CPejSxpc2wZ60beGFlw0viFstKMxmc400VBSlxvSJEyfYsWMH//znP7l06VKNbVesWGH5+oknnmDIkCF1eu3aPor+WwwGxxw0zBH7dsSewTH7bko9Gwwe9Ihqccvlj42O5KvUbL7cd47t32dZhiNqF+pFn8hgenYOotpsJreojILiCtq39KbzLT7P0VB9Wy0ogoKCSE1NtUzn5+cTEBBgmU5KSiI/P58HH3wQo9FIXl4ekyZNYtWqVWzYsIHp06cD1wNGo6nbXQIy1lPdOGLfjtgzOGbfzbHnuzv4c3cHfyqN1WTllnAiu5jDpwpYnZTB6qSMG9YP8HYhNjKIoXe3tDy4qVmM9RQbG8s777xDUVERLi4u7Nixg1deecWyfM6cOcyZMweAnJwcpk6dyieffEJ1dTUffvghMTExdO3aldWrV9f5iEIIIeyBk07z09P+vBnZpzXF1yr5IfMyznoNfl7OeLnpST9bxJ60i2z+7ixe7noGdgtp8DqsFhSBgYHEx8czdepUjEYj48ePJzo6mpkzZzJnzhyioqJuup1Go2H58uW89NJLVFRU0Lp1a5YsWWKtMoUQotnwdneiT2RQjXl9o4LpGxVMWYUJFyfrfEZDhhn/heZ4iNoQHLFvR+wZHLNvR+wZGvbUk4yjK4QQolYSFEIIIWolQSGEEKJWEhRCCCFqJUEhhBCiVhIUQgghamWXz6NQq+s/kNadbNucOWLfjtgzOGbfjtgz3H7fv7WeXX6OQgghRMORU09CCCFqJUEhhBCiVhIUQgghaiVBIYQQolYSFEIIIWolQSGEEKJWEhRCCCFqJUEhhBCiVhIUQgghaiVB8ZPExERGjBjB0KFDWbNmja3LsZp3332XkSNHMnLkSMsjZpOTkxk1ahRDhw5l2bJlNq7Qel5//XUSEhIAx+h5586djBs3jvvvv59FixYBjtH3li1bLL/jr7/+OmC/fV+7do24uDhycnKAW/f5ww8/MG7cOIYNG8Zf/vIXTCZT3V5IEcqlS5eUwYMHK5cvX1ZKS0uVUaNGKSdPnrR1WQ1uz549ysMPP6xUVlYqVVVVytSpU5XExERl4MCBSlZWlmI0GpUZM2Yo33zzja1LbXDJyclKr169lOeff14pLy+3+56zsrKUfv36KRcvXlSqqqqURx55RPnmm2/svu+ysjKlZ8+eSmFhoWI0GpXx48crX331lV32ffjwYSUuLk7p0qWLkp2dXevv9ciRI5VDhw4piqIoL7zwgrJmzZo6vZYcUXA9hXv37o23tzeurq4MGzaMpKQkW5fV4AwGAwkJCej1enQ6He3atSMzM5OwsDBatmyJVqtl1KhRdtd7cXExy5YtY9asWQAcPXrU7nv+4osvGDFiBEFBQeh0OpYtW4aLi4vd911dXY3ZbKa8vByTyYTJZMLd3d0u+16/fj0LFiwgICAAuPXv9fnz56moqKBbt24AjBs3rs792+XosXWVl5eHwWCwTAcEBHD06FEbVmQd7du3t3ydmZnJ559/zqOPPnpD77m5ubYoz2r++te/Eh8fz8WLF4Gb/7ztredz586h0+mYNWsWFy9eZNCgQbRv397u+3Z3d+ePf/wj999/Py4uLvTs2dNuf95/+9vfakzfqs9fzzcYDHXuX44oALPZjEr1v2F2FUWpMW1vTp48yYwZM3juuedo2bKlXff+6aefEhwcTJ8+fSzzHOHnXV1dTUpKCq+++irr1q3j6NGjZGdn233fGRkZbNiwga+//prdu3ejVqvJzMy0+77h1r/XDfH7LkcUQFBQEKmpqZbp/Px8y+GcvTlw4ABz5sxh3rx5jBw5kn379pGfn29Zbm+9b9++nfz8fMaMGcOVK1coKyvj/PnzaDQayzr21jOAv78/ffr0wdfXF4D77ruPpKQku+/7u+++o0+fPvj5+QHXT7N89NFHdt83XP87drP/y7+eX1BQUOf+5YgCiI2NJSUlhaKiIsrLy9mxYwcDBgywdVkN7uLFizz11FMsXbqUkSNHAtC1a1fOnj3LuXPnqK6uZtu2bXbV+z/+8Q+2bdvGli1bmDNnDvfccw8ffvihXfcMMHjwYL777juuXr1KdXU1u3fvZvjw4Xbfd6dOnUhOTqasrAxFUdi5c6fd/47/7FZ9hoSE4OTkxIEDB4Drd4XVtX85ogACAwOJj49n6tSpGI1Gxo8fT3R0tK3LanAfffQRlZWVLF682DJv4sSJLF68mD/84Q9UVlYycOBAhg8fbsMqrc/Jycnue+7atStPPPEEkyZNwmg00rdvXx555BHatm1r133369eP48ePM27cOHQ6HVFRUfzhD3+gb9++dt031P57vXTpUubPn8+1a9fo0qULU6dOrdO+5Ql3QgghaiWnnoQQQtRKgkIIIUStJCiEEELUSoJCCCFErSQohBBC1EpujxWiDjp27EiHDh1Qq2u+x1qxYgWhoaEN/lopKSmWD80JYSsSFELU0ccffyx/vIVDkaAQooHs3buXpUuX0qJFC86cOYOzszOLFy+mXbt2lJSU8PLLL5ORkYFKpaJ///48++yzaLVajhw5wqJFiygvL0en0/Hcc89ZxqZ65513OHLkCMXFxTz++ONMnjzZxl0KRyRBIUQdTZs2rcapp9DQUFasWAFAeno6zz//PD169GDt2rXMnTuXjRs3smjRIry9vUlMTMRoNDJ79mz+/ve/89hjj/HUU0+xaNEiBg0aRHp6Oi+88AJbtmwBoGXLlixYsIDjx4/z8MMPM2HCBHQ6nU36Fo5LgkKIOqrt1FOnTp3o0aMHAA8++CALFy7k8uXL7Nq1i7Vr16JSqdDr9UycOJGPP/6Yvn37olarGTRoEACRkZEkJiZa9hcXFwdAREQEVVVVXLt2DR8fH+s2KMSvyF1PQjSgX45S+st5vx7q2Ww2YzKZ0Gg0Nwz5fOLECcujKrXa6+/lfl5HRtwRtiBBIUQDysjIICMjA4B169YRExODp6cn/fr1Y/Xq1SiKQlVVFevXryc2Npa2bduiUqnYs2cPAMeOHWPatGmYzWZbtiFEDXLqSYg6+vU1CoBnn30WZ2dn/P39Wb58OefPn8fX15clS5YAMH/+fBYtWsSoUaMwGo3079+fWbNmodfreeedd3j11VdZsmQJOp2Od955B71eb4vWhLgpGT1WiAayd+9eXnnlFbZt22brUoRoUHLqSQghRK3kiEIIIUSt5IhCCCFErSQohBBC1EqCQgghRK0kKIQQQtRKgkIIIUStJCiEEELU6v8Df9L7A59nZlMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "L_2 = [T.detach().numpy() for T in total_L]\n",
    "\n",
    "L_2 = np.array(L_2)\n",
    "\n",
    "plt.figure()\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "plt.plot(L_2)\n",
    "plt.title('Evolution of the loss')\n",
    "plt.xlabel('Epoch');plt.ylabel('Loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test : 65 %\n",
      "Weighted F1-score on test : 65 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "y_pred, y_true = [], []\n",
    "\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        X_test, labels = data\n",
    "        X_test, labels = X_test.float(), labels.type(torch.LongTensor)\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = CNN(X_test)\n",
    "\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        y_true.extend(labels.tolist())\n",
    "        y_pred.extend(predicted.tolist())\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "TOT_ACC = 100 * correct / total\n",
    "F1 = 100 * f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print('Accuracy on test : %d %%' % (TOT_ACC))\n",
    "print('Weighted F1-score on test : %d %%' % (F1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare to count predictions for each class\n",
    "classes = ('FNSZ','GNSZ')\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        X_test, labels = data\n",
    "        X_test, labels = X_test.float(), labels.type(torch.LongTensor)\n",
    "        outputs = CNN(X_test)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "### DIVIDE BY TRUE TOTAL NB OF FNSZ & GNSZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss :  0.446736\n",
      "Unweighted total accuracy on test : 65.4 %\n",
      "Weighted F1-score on test : 65.9 %\n",
      "Accuracy for FNSZ  is: 67.0 %\n",
      "Accuracy for GNSZ  is: 62.6 %\n"
     ]
    }
   ],
   "source": [
    "print('Final loss : ',round(total_L[-1].item(),6))\n",
    "print(f'Unweighted total accuracy on test : {round(TOT_ACC,1)} %')\n",
    "print(f'Weighted F1-score on test : {round(F1,1)} %')\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(\"Accuracy for {:5s} is: {:.1f} %\".format(classname, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ca02964d08fc28c71d2bf17a5c1f94340d35561783d4e82c93d82793d6a36248"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
