{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this if using cov matrix\n",
    "is_cov = True\n",
    "\n",
    "\n",
    "\n",
    "# Keep data in 2D for 2D convolution of the NN\n",
    "def load_graphs(input_dir, class_dict) :\n",
    "\n",
    "    data, data_labels = [], [] # data containing the graphs and data_labels the associated seizure type labels\n",
    "    i=0\n",
    "    for szr_type in class_dict.keys() :\n",
    "        szr_label = class_dict[szr_type]\n",
    "        for _, _, files in os.walk(os.path.join(input_dir,szr_type)) :\n",
    "            for npy_file in files :\n",
    "                A = np.load(os.path.join(input_dir,szr_type,npy_file))\n",
    "\n",
    "                # Normalise A (already normalised depending on the input)\n",
    "                #A = A/np.amax(A.flatten())\n",
    "                if is_cov : \n",
    "                    L = torch.tensor(A/np.amax(A.flatten())).view(1,20,20)\n",
    "                else : \n",
    "                    L = torch.tensor(np.diag(A*np.ones((A.shape[0],1)))-A).view(1,20,20)\n",
    "                    #L = torch.tensor(A).view(1,20,20)\n",
    "\n",
    "                data.append(L)\n",
    "                data_labels.append(szr_label)\n",
    "\n",
    "    return np.array(data), np.array(data_labels)\n",
    "\n",
    "def train_test_data(input_dir, class_dict) :\n",
    "\n",
    "    train, train_labels = load_graphs(os.path.join(input_dir,'train'), class_dict)\n",
    "    test, test_labels = load_graphs(os.path.join(input_dir,'dev'), class_dict)\n",
    "\n",
    "    return train, test, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rapha\\AppData\\Local\\Temp/ipykernel_19060/2000065660.py:28: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  return np.array(data), np.array(data_labels)\n",
      "C:\\Users\\rapha\\AppData\\Local\\Temp/ipykernel_19060/2000065660.py:28: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(data), np.array(data_labels)\n"
     ]
    }
   ],
   "source": [
    "# Need to put it as a torch.Size([1, 20, 20])\n",
    "input_dir = '../data/v1.5.2/graph_cov_low'\n",
    "#input_dir = '../data/v1.5.2/graph_avg_1_5'\n",
    "szr_types = ['FNSZ','GNSZ']\n",
    "\n",
    "class_dict = {}\n",
    "for i, szr_type in enumerate(szr_types) :\n",
    "    class_dict[szr_type] = i\n",
    "\n",
    "train, test, train_labels, test_labels = train_test_data(input_dir, class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536  vs  409\n",
      "3\n",
      "309\n"
     ]
    }
   ],
   "source": [
    "# Oversampling (train set only) to have balanced classification without dropping information\n",
    "PD = pd.DataFrame(train_labels,columns=['label'])\n",
    "no_0, no_1 = len(PD[PD['label']==0]), len(PD[PD['label']==1])\n",
    "print(no_0, ' vs ', no_1)\n",
    "\n",
    "R = math.floor(no_0/no_1)\n",
    "print(R) # Multiply the dataset by this ratio, then add (no_0 - R*no_1) randomly selected entries from the smallest dataset\n",
    "print(no_0 - R*no_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "trainset, testset = [], []\n",
    "for i in range(len(train)) :\n",
    "    if train_labels[i] == 1 : # Under-represented class :\n",
    "        # The dataloader later shuffles the data\n",
    "        for r in range(R) :\n",
    "            trainset.append((train[i],train_labels[i]))\n",
    "    else :\n",
    "        trainset.append((train[i],train_labels[i]))\n",
    "\n",
    "# Compensate the remaining imbalance => draw (no_0 - R*no_1) elements from already present elements\n",
    "Add = random.sample(PD[PD['label']==1].index.to_list(),no_0 - R*no_1)\n",
    "for idx in Add :\n",
    "    trainset.append((train[idx],train_labels[idx]))\n",
    "\n",
    "for j in range(len(test)) :\n",
    "    testset.append((test[j],test_labels[j]))\n",
    "classes = ('FNSZ','GNSZ')\n",
    "\n",
    "#trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "#testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536  vs  1536\n"
     ]
    }
   ],
   "source": [
    "len(trainset)\n",
    "tmp_set = []\n",
    "for s in trainset :\n",
    "    tmp_set.append(s[1])\n",
    "\n",
    "PD_tmp = pd.DataFrame(tmp_set,columns=['label'])\n",
    "tmp_0, tmp_1 = len(PD_tmp[PD_tmp['label']==0]), len(PD_tmp[PD_tmp['label']==1])\n",
    "print(tmp_0, ' vs ', tmp_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.fc1 = nn.Linear(16 * 3 * 3, 80)\n",
    "        self.fc2 = nn.Linear(80, 40)\n",
    "        self.fc3 = nn.Linear(40, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nclass Net_2(nn.Module):\\n    def __init__(self):\\n        super().__init__()\\n        self.conv1 = nn.Conv2d(3, 6, 5)\\n        self.pool = nn.MaxPool2d(2, 2)\\n        self.conv2 = nn.Conv2d(6, 16, 5)\\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\\n        self.fc2 = nn.Linear(120, 84)\\n        self.fc3 = nn.Linear(84, 10)\\n\\n    def forward(self, x):\\n        x = self.pool(F.relu(self.conv1(x)))\\n        x = self.pool(F.relu(self.conv2(x)))\\n        print('Before : ',x.shape)\\n        x = torch.flatten(x, 1) # flatten all dimensions except batch\\n        print('After : ',x.shape)\\n        x = F.relu(self.fc1(x))\\n        x = F.relu(self.fc2(x))\\n        x = self.fc3(x)\\n        return x\\n\\nCNN = Net_2()\\nCNN = CNN.float()\\ncriterion = nn.CrossEntropyLoss()\\noptimizer = optim.SGD(CNN.parameters(), lr=0.001, momentum=0.9)\\n\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "class Net_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        print('Before : ',x.shape)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        print('After : ',x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "CNN = Net_2()\n",
    "CNN = CNN.float()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(CNN.parameters(), lr=0.001, momentum=0.9)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=144, out_features=80, bias=True)\n",
      "  (fc2): Linear(in_features=80, out_features=40, bias=True)\n",
      "  (fc3): Linear(in_features=40, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Run forward pass once and check flattened output dimensions\n",
    "CNN = Net()\n",
    "CNN = CNN.float()\n",
    "print(CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 1e-4\n",
    "loss_criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(CNN.parameters(), lr=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch_size :  50 \n",
      "Learning rate :  0.0001\n",
      "Epoch : 0, Loss : 0.6914\n",
      "Epoch : 1, Loss : 0.6893\n",
      "Epoch : 2, Loss : 0.6859\n",
      "Epoch : 3, Loss : 0.681\n",
      "Epoch : 4, Loss : 0.6727\n",
      "Epoch : 5, Loss : 0.6614\n",
      "Epoch : 6, Loss : 0.6486\n",
      "Epoch : 7, Loss : 0.6382\n",
      "Epoch : 8, Loss : 0.6295\n",
      "Epoch : 9, Loss : 0.6202\n",
      "Epoch : 10, Loss : 0.6113\n",
      "Epoch : 11, Loss : 0.6022\n",
      "Epoch : 12, Loss : 0.5948\n",
      "Epoch : 13, Loss : 0.5875\n",
      "Epoch : 14, Loss : 0.5775\n",
      "Epoch : 15, Loss : 0.5693\n",
      "Epoch : 16, Loss : 0.5613\n",
      "Epoch : 17, Loss : 0.5543\n",
      "Epoch : 18, Loss : 0.5493\n",
      "Epoch : 19, Loss : 0.5422\n",
      "Epoch : 20, Loss : 0.5373\n",
      "Epoch : 21, Loss : 0.5359\n",
      "Epoch : 22, Loss : 0.5294\n",
      "Epoch : 23, Loss : 0.5265\n",
      "Epoch : 24, Loss : 0.5254\n",
      "Epoch : 25, Loss : 0.5213\n",
      "Epoch : 26, Loss : 0.5176\n",
      "Epoch : 27, Loss : 0.5152\n",
      "Epoch : 28, Loss : 0.5129\n",
      "Epoch : 29, Loss : 0.5101\n",
      "Epoch : 30, Loss : 0.5074\n",
      "Epoch : 31, Loss : 0.5053\n",
      "Epoch : 32, Loss : 0.5059\n",
      "Epoch : 33, Loss : 0.5037\n",
      "Epoch : 34, Loss : 0.5003\n",
      "Epoch : 35, Loss : 0.4997\n",
      "Epoch : 36, Loss : 0.4977\n",
      "Epoch : 37, Loss : 0.4959\n",
      "Epoch : 38, Loss : 0.4951\n",
      "Epoch : 39, Loss : 0.4949\n",
      "Epoch : 40, Loss : 0.4921\n",
      "Epoch : 41, Loss : 0.4899\n",
      "Epoch : 42, Loss : 0.4886\n",
      "Epoch : 43, Loss : 0.4871\n",
      "Epoch : 44, Loss : 0.487\n",
      "Epoch : 45, Loss : 0.4858\n",
      "Epoch : 46, Loss : 0.4846\n",
      "Epoch : 47, Loss : 0.4824\n",
      "Epoch : 48, Loss : 0.4804\n",
      "Epoch : 49, Loss : 0.4802\n",
      "Epoch : 50, Loss : 0.4792\n",
      "Epoch : 51, Loss : 0.4766\n",
      "Epoch : 52, Loss : 0.4762\n",
      "Epoch : 53, Loss : 0.4763\n",
      "Epoch : 54, Loss : 0.4748\n",
      "Epoch : 55, Loss : 0.4723\n",
      "Epoch : 56, Loss : 0.4714\n",
      "Epoch : 57, Loss : 0.4711\n",
      "Epoch : 58, Loss : 0.4696\n",
      "Epoch : 59, Loss : 0.4683\n",
      "Epoch : 60, Loss : 0.4686\n",
      "Epoch : 61, Loss : 0.4661\n",
      "Epoch : 62, Loss : 0.4648\n",
      "Epoch : 63, Loss : 0.4667\n",
      "Epoch : 64, Loss : 0.4639\n",
      "Epoch : 65, Loss : 0.4628\n",
      "Epoch : 66, Loss : 0.4625\n",
      "Epoch : 67, Loss : 0.4625\n",
      "Epoch : 68, Loss : 0.4605\n",
      "Epoch : 69, Loss : 0.4605\n",
      "Epoch : 70, Loss : 0.4597\n",
      "Epoch : 71, Loss : 0.4584\n",
      "Epoch : 72, Loss : 0.4572\n",
      "Epoch : 73, Loss : 0.4581\n",
      "Epoch : 74, Loss : 0.4558\n",
      "Epoch : 75, Loss : 0.4554\n",
      "Epoch : 76, Loss : 0.4534\n",
      "Epoch : 77, Loss : 0.4545\n",
      "Epoch : 78, Loss : 0.4546\n",
      "Epoch : 79, Loss : 0.4531\n",
      "Epoch : 80, Loss : 0.4512\n",
      "Epoch : 81, Loss : 0.4514\n",
      "Epoch : 82, Loss : 0.451\n",
      "Epoch : 83, Loss : 0.4498\n",
      "Epoch : 84, Loss : 0.4499\n",
      "Epoch : 85, Loss : 0.4501\n",
      "Epoch : 86, Loss : 0.4484\n",
      "Epoch : 87, Loss : 0.4477\n",
      "Epoch : 88, Loss : 0.4466\n",
      "Epoch : 89, Loss : 0.447\n",
      "Epoch : 90, Loss : 0.4465\n",
      "Epoch : 91, Loss : 0.4458\n",
      "Epoch : 92, Loss : 0.446\n",
      "Epoch : 93, Loss : 0.4443\n",
      "Epoch : 94, Loss : 0.4445\n",
      "Epoch : 95, Loss : 0.4428\n",
      "Epoch : 96, Loss : 0.4425\n",
      "Epoch : 97, Loss : 0.4425\n",
      "Epoch : 98, Loss : 0.4409\n",
      "Epoch : 99, Loss : 0.4421\n"
     ]
    }
   ],
   "source": [
    "total_L, total_acc = [], []\n",
    "print('Batch_size : ',batch_size,'\\nLearning rate : ',gamma)\n",
    "for epoch in range(100): \n",
    "    i = 0\n",
    "    temp_L = []\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in trainloader:\n",
    "        X, y = data\n",
    "        optimizer.zero_grad()\n",
    "        X, y = X.float(), y.type(torch.LongTensor)\n",
    "        output = CNN(X)\n",
    "\n",
    "        loss = loss_criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        temp_L.append(loss)\n",
    "\n",
    "        i += 1\n",
    "    total_L.append(sum(temp_L)/float(len(temp_L)))\n",
    "    print(f\"Epoch : {epoch}, Loss : {round(total_L[-1].item(),6)}\")\n",
    "    #print('Accuracy of the network on the train graphs : %d %%' % (100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "L_2 = [T.detach().numpy() for T in total_L]\n",
    "\n",
    "L_2 = np.array(L_2)\n",
    "\n",
    "plt.figure()\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "plt.plot(L_2)\n",
    "plt.title('Evolution of the loss')\n",
    "plt.xlabel('Epoch');plt.ylabel('Loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test : 66 %\n",
      "Weighted F1-score on test : 66 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "y_pred, y_true = [], []\n",
    "\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        X_test, labels = data\n",
    "        X_test, labels = X_test.float(), labels.type(torch.LongTensor)\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = CNN(X_test)\n",
    "\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        y_true.extend(labels.tolist())\n",
    "        y_pred.extend(predicted.tolist())\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "TOT_ACC = 100 * correct / total\n",
    "F1 = 100 * f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print('Accuracy on test : %d %%' % (TOT_ACC))\n",
    "print('Weighted F1-score on test : %d %%' % (F1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare to count predictions for each class\n",
    "classes = ('FNSZ','GNSZ')\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        X_test, labels = data\n",
    "        X_test, labels = X_test.float(), labels.type(torch.LongTensor)\n",
    "        outputs = CNN(X_test)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "### DIVIDE BY TRUE TOTAL NB OF FNSZ & GNSZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss :  0.442111\n",
      "Unweighted total accuracy on test : 66.0 %\n",
      "Weighted F1-score on test : 66.6 %\n",
      "Accuracy for FNSZ  is: 65.0 %\n",
      "Accuracy for GNSZ  is: 67.8 %\n"
     ]
    }
   ],
   "source": [
    "print('Final loss : ',round(total_L[-1].item(),6))\n",
    "print(f'Unweighted total accuracy on test : {round(TOT_ACC,1)} %')\n",
    "print(f'Weighted F1-score on test : {round(F1,1)} %')\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(\"Accuracy for {:5s} is: {:.1f} %\".format(classname, accuracy))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ca02964d08fc28c71d2bf17a5c1f94340d35561783d4e82c93d82793d6a36248"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
