{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def over_connected(graph, upper, is_cov, revert) :\n",
    "\n",
    "    G = graph.flatten()\n",
    "    cross_thr, full_thr = 90, 90\n",
    "    # No such over-connected graphs in covariance matrices and not same thresholds with Laplacian (revert==True)\n",
    "    if is_cov or revert : \n",
    "        return False\n",
    "    # If on full symmetric matrix, the threshold count of pixels has to be doubled\n",
    "    if not upper :\n",
    "        cross_thr = 2*cross_thr\n",
    "        full_thr = 2*full_thr\n",
    "    if (G > 0.6).sum() >= cross_thr :\n",
    "        return True\n",
    "    elif (G > 0.4).sum() >= full_thr : \n",
    "        return True\n",
    "    else : \n",
    "        return False\n",
    "\n",
    "def load_graphs(input_dir, class_dict, is_cov, upper, revert, over_conn) :\n",
    "\n",
    "    data, data_labels = [], [] # data contains the graphs as tensors and data_labels the associated seizure type labels\n",
    "    i = 0\n",
    "\n",
    "    for szr_type in class_dict.keys() :\n",
    "\n",
    "        szr_label = class_dict[szr_type]\n",
    "        for _, _, files in os.walk(os.path.join(input_dir,szr_type)) :\n",
    "            \n",
    "            for npy_file in files :\n",
    "                A = np.load(os.path.join(input_dir,szr_type,npy_file))\n",
    "                # Normalise A (already normalised depending on the input)\n",
    "                A = A/np.amax(A.flatten())\n",
    "\n",
    "                if not is_cov and revert : \n",
    "                    L = np.diag(np.sum(A,axis=1)) - A\n",
    "                else : \n",
    "                    L = A\n",
    "                \n",
    "                # Only keep upper triangle as matrix is symmetric\n",
    "                if upper : L = np.triu(L, 0)\n",
    "\n",
    "                if over_conn : is_over_conn = over_connected(L, upper=upper, is_cov=is_cov, revert=revert)\n",
    "                else : is_over_conn = False\n",
    "\n",
    "                if not is_over_conn :\n",
    "\n",
    "                    # Change to tensor and reshape for dataloader\n",
    "                    L = torch.tensor(L).view(1,20,20)\n",
    "                    \n",
    "                    data.append(L)\n",
    "                    data_labels.append(szr_label)\n",
    "\n",
    "    return np.array(data, dtype=object), np.array(data_labels)\n",
    "\n",
    "def train_test_data(input_dir, class_dict, is_cov, upper, revert, over_conn) :\n",
    "\n",
    "    train, train_labels = load_graphs(os.path.join(input_dir,'train'), class_dict, is_cov, upper, revert, over_conn)\n",
    "    test, test_labels = load_graphs(os.path.join(input_dir,'dev'), class_dict, is_cov, upper, revert, over_conn)\n",
    "\n",
    "    return train, test, train_labels, test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(input_dir, class_dict, is_cov, upper, revert, over_conn) :\n",
    "\n",
    "    data, data_labels = [], [] # data contains the graphs as tensors and data_labels the associated seizure type labels\n",
    "\n",
    "    train_ids, test_ids = [], []\n",
    "\n",
    "    tot = 0\n",
    "\n",
    "    for set_ in ['train','dev'] :\n",
    "\n",
    "        for szr_type in class_dict.keys() :\n",
    "\n",
    "            szr_label = class_dict[szr_type]\n",
    "            for _, _, files in os.walk(os.path.join(input_dir,set_,szr_type)) :\n",
    "                \n",
    "                for npy_file in files :\n",
    "                    A = np.load(os.path.join(input_dir,set_,szr_type,npy_file))\n",
    "                    # Normalise A (already normalised depending on the input)\n",
    "                    A = A/np.amax(A.flatten())\n",
    "\n",
    "                    if not is_cov and revert : \n",
    "                        L = np.diag(np.sum(A,axis=1)) - A\n",
    "                    else : \n",
    "                        L = A\n",
    "                    \n",
    "                    # Only keep upper triangle as matrix is symmetric\n",
    "                    if upper : L = np.triu(L, 0)\n",
    "\n",
    "                    if over_conn : is_over_conn = over_connected(L, upper=upper, is_cov=is_cov, revert=revert)\n",
    "                    else : is_over_conn = False\n",
    "\n",
    "                    if not is_over_conn and (((set_ == 'dev') and (int(npy_file.split('_')[3]) not in [1027, 6546])) or set_=='train') : \n",
    "\n",
    "                        # Change to tensor and reshape for dataloader\n",
    "                        L = torch.tensor(L).view(1,20,20)\n",
    "                        \n",
    "                        data.append(L)\n",
    "                        data_labels.append(szr_label)\n",
    "\n",
    "                        p_id = npy_file.split('_')[3]\n",
    "\n",
    "                        tot += 1\n",
    "\n",
    "                        if set_ == 'train' : train_ids.append(int(p_id))\n",
    "                        else : test_ids.append(int(p_id))\n",
    "    \n",
    "    print('Total : ',tot)\n",
    "\n",
    "    return np.array(data, dtype=object), np.array(data_labels), train_ids, test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total :  2344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rapha\\AppData\\Local\\Temp/ipykernel_25596/962385938.py:49: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  return np.array(data, dtype=object), np.array(data_labels), train_ids, test_ids\n"
     ]
    }
   ],
   "source": [
    "input_dir = '../data/v1.5.2/graph_lapl_low_50'\n",
    "is_cov = False\n",
    "upper = True\n",
    "revert = False\n",
    "over_conn = False\n",
    "\n",
    "classes = ['FNSZ','GNSZ']\n",
    "\n",
    "class_dict = {}\n",
    "for i, szr_type in enumerate(classes) :\n",
    "    class_dict[szr_type] = i\n",
    "\n",
    "# Load all graphs :\n",
    "data, data_labels, train_ids, test_ids = load_data(input_dir, class_dict, is_cov, upper, revert, over_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399\n"
     ]
    }
   ],
   "source": [
    "print(len(test_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "#train_ids = list(dict.fromkeys(train_ids))\n",
    "#test_ids = list(dict.fromkeys(test_ids))\n",
    "\n",
    "# Sort the lists\n",
    "train_ids.sort()\n",
    "test_ids.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1945\n",
      "75\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ids))\n",
    "print(len(test_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train :\\n',train_ids,'\\nTest :\\n',test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in train_ids :\n",
    "    if id in test_ids :\n",
    "        print('In both : ',id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ca02964d08fc28c71d2bf17a5c1f94340d35561783d4e82c93d82793d6a36248"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
